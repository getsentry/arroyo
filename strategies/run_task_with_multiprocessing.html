<!DOCTYPE html>
<html lang="en" data-accent-color="violet" data-content_root="../">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Run Task with Multiprocessing - Arroyo documentation</title><link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Produce" href="produce.html" /><link rel="prev" title="Run Task in Threads" href="run_task_in_threads.html" /><script>
    function setColorMode(t){let e=document.documentElement;e.setAttribute("data-color-mode",t);let a=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,s=t;"auto"===t&&(s=a?"dark":"light"),"light"===s?(e.classList.remove("dark"),e.classList.add("light")):(e.classList.remove("light"),e.classList.add("dark"))}
    setColorMode(localStorage._theme||"auto");
  </script><link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=ad592e98" />
    <link rel="stylesheet" type="text/css" href="../_static/shibuya.css?v=d140fbf8" />
    <link media="print" rel="stylesheet" type="text/css" href="../_static/print.css?v=20ff2c19" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=d78f5285" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
:root {
  --sy-f-text: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
  --sy-f-heading: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
}
</style>
    <meta property="og:type" content="website"/><meta property="og:title" content="Run Task with Multiprocessing"/>
<meta name="twitter:card" content="summary"/>
  </head>
<body><div class="sy-head">
  <div class="sy-head-blur"></div>
  <div class="sy-head-inner sy-container mx-auto">
    <a class="sy-head-brand" href="../index.html">
      <img class="light-logo" src="../_static/arroyo-logo.png" alt="Arroyo" height="28" loading="lazy" />
      <img class="dark-logo" src="../_static/arroyo-logo.png" alt="Arroyo" height="28" loading="lazy" />
      <strong>Arroyo</strong>
    </a>
    <div class="sy-head-nav" id="head-nav">
      <nav class="sy-head-links"></nav>
      <div class="sy-head-extra flex items-center print:hidden"><form class="searchbox flex items-center" action="../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <kbd>/</kbd>
</form><div class="sy-head-socials"></div></div>
    </div>
    <div class="sy-head-actions flex items-center shrink-0 print:hidden"><button class="js-theme theme-switch flex items-center"
data-aria-auto="Switch to light color mode"
data-aria-light="Switch to dark color mode"
data-aria-dark="Switch to auto color mode">
<i class="i-lucide theme-icon"></i>
</button><button class="md:hidden flex items-center js-menu" aria-label="Menu" type="button" aria-controls="head-nav" aria-expanded="false">
        <div class="hamburger">
          <span class="hamburger_1"></span>
          <span class="hamburger_2"></span>
          <span class="hamburger_3"></span>
        </div>
      </button>
    </div>
  </div>
</div>
<div class="sy-page sy-container flex mx-auto">
  <aside id="lside" class="sy-lside md:w-72 md:shrink-0 print:hidden">
    <div class="sy-lside-inner md:sticky">
      <div class="sy-scrollbar p-6">
        <div class="globaltoc" data-expand-depth="0"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../what_for.html">What is Arroyo for?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getstarted.html">Getting started with Arroyo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../architecture.html">Arroyo Architecture</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Processing Strategies</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="filter.html">Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="reduce.html">Reduce (Fold)</a></li>
<li class="toctree-l2"><a class="reference internal" href="unfold.html">Unfold</a></li>
<li class="toctree-l2"><a class="reference internal" href="batching.html">Batch and Unbatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="run_task.html">Run Task</a></li>
<li class="toctree-l2"><a class="reference internal" href="run_task_in_threads.html">Run Task in Threads</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Run Task with Multiprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="produce.html">Produce</a></li>
<li class="toctree-l2"><a class="reference internal" href="commit_offsets.html">Commit offsets</a></li>
<li class="toctree-l2"><a class="reference internal" href="noop.html">Noop</a></li>
<li class="toctree-l2"><a class="reference internal" href="healthcheck.html">Healthchecks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../offsets.html">Committing offsets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dlqs.html">Dead letter queues</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backpressure.html">Backpressure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parameters.html">Common consumer parameters</a></li>
</ul>

        </div>
      </div>
    </div>
  </aside>
  <div class="lside-overlay js-menu" role="button" aria-label="Close left sidebar" aria-controls="lside" aria-expanded="false"></div>
  <aside id="rside" class="sy-rside pb-3 w-64 shrink-0 order-last">
    <button class="rside-close js-menu xl:hidden" aria-label="Close Table of Contents" type="button" aria-controls="rside" aria-expanded="false">
      <i class="i-lucide close"></i>
    </button>
    <div class="sy-scrollbar sy-rside-inner px-6 xl:top-16 xl:sticky xl:pl-0 pt-6 pb-4"><div class="localtoc"><h3>On this page</h3><ul>
<li><a class="reference internal" href="#arroyo.processing.strategies.run_task_with_multiprocessing.RunTaskWithMultiprocessing"><code class="docutils literal notranslate"><span class="pre">RunTaskWithMultiprocessing</span></code></a></li>
</ul>
</div><div id="ethical-ad-placement" data-ea-publisher="readthedocs"></div></div>
  </aside>
  <div class="rside-overlay js-menu" role="button" aria-label="Close Table of Contents" aria-controls="rside" aria-expanded="false"></div>
  <main class="sy-main w-full max-sm:max-w-full print:pt-6">
<div class="sy-breadcrumbs" role="navigation">
  <div class="sy-breadcrumbs-inner flex items-center">
    <div class="md:hidden mr-3">
      <button class="js-menu" aria-label="Menu" type="button" aria-controls="lside" aria-expanded="false">
        <i class="i-lucide menu"></i>
      </button>
    </div>
    <ol class="flex-1" itemscope itemtype="https://schema.org/BreadcrumbList"><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../index.html"><span itemprop="name">Arroyo</span></a>
        <span>/</span>
        <meta itemprop="position" content="1" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="index.html"><span itemprop="name">Processing Strategies</span></a>
        <span>/</span>
        <meta itemprop="position" content="2" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <strong itemprop="name">Run Task with Multiprocessing</strong>
        <meta itemprop="position" content="3" />
      </li></ol>
    <div class="xl:hidden ml-1">
      <button class="js-menu" aria-label="Show table of contents" type="button" aria-controls="rside"
        aria-expanded="false">
        <i class="i-lucide outdent"></i>
      </button>
    </div>
  </div>
</div><div class="flex flex-col break-words justify-between">
      <div class="min-w-0 max-w-6xl px-6 pb-6 pt-8 xl:px-12">
        <article class="yue" role="main">
          <section id="module-arroyo.processing.strategies.run_task_with_multiprocessing">
<span id="run-task-with-multiprocessing"></span><h1>Run Task with Multiprocessing<a class="headerlink" href="#module-arroyo.processing.strategies.run_task_with_multiprocessing" title="Link to this heading">Â¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="arroyo.processing.strategies.run_task_with_multiprocessing.RunTaskWithMultiprocessing">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">arroyo.processing.strategies.run_task_with_multiprocessing.</span></span><span class="sig-name descname"><span class="pre">RunTaskWithMultiprocessing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">function</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="index.html#arroyo.types.Message" title="arroyo.types.Message"><span class="pre">Message</span></a><span class="p"><span class="pre">[</span></span><span class="pre">TStrategyPayload</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">TResult</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">next_step</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="index.html#arroyo.processing.strategies.abstract.ProcessingStrategy" title="arroyo.processing.strategies.abstract.ProcessingStrategy"><span class="pre">ProcessingStrategy</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="index.html#arroyo.types.FilteredPayload" title="arroyo.types.FilteredPayload"><span class="pre">FilteredPayload</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">TResult</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_batch_time</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">MultiprocessingPool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_block_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_block_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_input_block_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_output_block_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefetch_batches</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#arroyo.processing.strategies.run_task_with_multiprocessing.RunTaskWithMultiprocessing" title="Link to this definition">Â¶</a></dt>
<dd><p>Run a function in parallel across messages using subprocesses.</p>
<p><code class="docutils literal notranslate"><span class="pre">RunTaskWithMultiprocessing</span></code> uses the <code class="docutils literal notranslate"><span class="pre">multiprocessing</span></code> stdlib module to
transform messages in parallel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>function</strong> â The function to use for transforming.</p></li>
<li><p><strong>next_step</strong> â The processing strategy to forward transformed messages to.</p></li>
<li><p><strong>max_batch_size</strong> â Wait at most for this many messages before âclosingâ a batch.</p></li>
<li><p><strong>max_batch_time</strong> â Wait at most for this many seconds before closing a batch.</p></li>
<li><p><strong>pool</strong> â The multiprocessing pool to use for parallel processing. The same pool
instance can be re-used each time <code class="docutils literal notranslate"><span class="pre">RunTaskWithMultiprocessing</span></code> is created on
rebalance.</p></li>
<li><p><strong>input_block_size</strong> â <p>For each subprocess, a shared memory buffer of
<code class="docutils literal notranslate"><span class="pre">input_block_size</span></code> is allocated. This value should be at least
<cite>message_size * max_batch_size</cite> large, where <cite>message_size</cite> is the expected
average message size.</p>
<p>If the value is too small, the batch is implicitly broken up. In that
case, the
<code class="docutils literal notranslate"><span class="pre">arroyo.strategies.run_task_with_multiprocessing.batch.input.overflow</span></code>
metric is emitted.</p>
<p>If the value is set to <cite>None</cite>, the <cite>input_block_size</cite> is automatically
adjusted to adapt to traffic. Keep in mind that this is a rather
experimental feature and less productionized than explicitly setting a
value.</p>
</p></li>
<li><p><strong>output_block_size</strong> â <p>Size of the shared memory buffer used to store
results. Like with input data, the batch is implicitly broken up on
overflow, and
<code class="docutils literal notranslate"><span class="pre">arroyo.strategies.run_task_with_multiprocessing.batch.output.overflow</span></code>
metric is incremented.</p>
<p>Like with <cite>input_block_size</cite>, the value can be set to <cite>None</cite> to enable
automatic resizing.</p>
</p></li>
<li><p><strong>max_input_block_size</strong> â If automatic resizing is enabled, this sets an
upper limit on how large those blocks can get.</p></li>
<li><p><strong>max_output_block_size</strong> â Same as <cite>max_input_block_size</cite> but for output
blocks.</p></li>
</ul>
</dd>
</dl>
<section id="number-of-processes">
<h2>Number of processes<a class="headerlink" href="#number-of-processes" title="Link to this heading">Â¶</a></h2>
<p>The metric
<code class="docutils literal notranslate"><span class="pre">arroyo.strategies.run_task_with_multiprocessing.batches_in_progress</span></code>
shows you how many processes arroyo is able to effectively use at any given
point.</p>
<p>The metric <code class="docutils literal notranslate"><span class="pre">arroyo.strategies.run_task_with_multiprocessing.processes</span></code>
shows how many processes arroyo was configured with.</p>
<p>If those two metrics donât line up, your consumer is not bottlenecked on
number of processes. Thatâs a good thing, you want to have some reserve
capacity. But it means that increasing <code class="docutils literal notranslate"><span class="pre">num_processes</span></code> will not make your
consumer faster.</p>
</section>
<section id="batching">
<h2>Batching<a class="headerlink" href="#batching" title="Link to this heading">Â¶</a></h2>
<p>Arroyo sends messages in batches to subprocesses. <code class="docutils literal notranslate"><span class="pre">max_batch_size</span></code> and <code class="docutils literal notranslate"><span class="pre">max_batch_time</span></code>
should be tweaked for optimal performance. You can observe the effect in the following metrics:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">arroyo.strategies.run_task_with_multiprocessing.batch.size.msg</span></code>: The number of messages per batch.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">arroyo.strategies.run_task_with_multiprocessing.batch.size.bytes</span></code>: The number of bytes used per batch.</p></li>
</ul>
<p>The cost of batches (locking, synchronization) generally amortizes with
increased batch sizes. Too small batches, and this strategy will spend a
lot of time synchronizing between processes. Too large batches, however,
can cause your consumer to not use all processes effectively, as a lot of
time may be spent waiting for batches to fill up.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">batch.size.msg</span></code> is flat (as in, itâs a perfectly straight line at a
constant), you are hitting <code class="docutils literal notranslate"><span class="pre">max_batch_size</span></code>. If <code class="docutils literal notranslate"><span class="pre">batch.size.bytes</span></code> is
flat, you are hitting input buffer overflow (see next section). If neither
are flat, you are hitting <code class="docutils literal notranslate"><span class="pre">max_batch_time</span></code>.</p>
</section>
<section id="input-and-output-buffers">
<h2>Input and output buffers<a class="headerlink" href="#input-and-output-buffers" title="Link to this heading">Â¶</a></h2>
<p>You want to keep an eye on these metrics:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">arroyo.strategies.run_task_with_multiprocessing.batch.input.overflow</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">arroyo.strategies.run_task_with_multiprocessing.batch.output.overflow</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">arroyo.strategies.run_task_with_multiprocessing.batch.backpressure</span></code></p></li>
</ol>
<p>If <code class="docutils literal notranslate"><span class="pre">batch.input.overflow</span></code> is emitted at all, arroyo ran out of memory for
batching and started breaking up your batches into smaller ones. You want
to increase <code class="docutils literal notranslate"><span class="pre">input_block_size</span></code> in response. Note that when you do this,
you may have to re-tweak <code class="docutils literal notranslate"><span class="pre">max_batch_size</span></code> and <code class="docutils literal notranslate"><span class="pre">max_batch_time</span></code>, as you
were never hitting those configured limits before. Input overflow is not
really all that expensive in Arroyo, but since it affects how batching
works it can still make performance tuning of your consumer more confusing.
Best to avoid it anyway.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">batch.output.overflow</span></code> is emitted at all, arroyo ran out of memory
when <em>fetching</em> the data from subprocesses, and so the response from
subprocesses to the main processes is chunked. Output overflow is very
expensive, and you want to avoid it. Increase <code class="docutils literal notranslate"><span class="pre">output_block_size</span></code> in
response.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">batch.backpressure</span></code> is continuously emitted, you are not bottlenecked
on multiprocessing at all, but instead the next strategy canât keep up and
is applying backpressure. You can likely reduce <code class="docutils literal notranslate"><span class="pre">num_processes</span></code> and wonât
notice a performance regression.</p>
</section>
<section id="prefetching">
<h2>Prefetching<a class="headerlink" href="#prefetching" title="Link to this heading">Â¶</a></h2>
<p>If you set <code class="docutils literal notranslate"><span class="pre">prefetch_batches</span></code> to <cite>True</cite>, Arroyo will allocate twice as
many input blocks as processes, and will prefetch the next batch while the
current batch is being processed. This can help saturate the process pool to
increase throughput, but it also increases memory usage.</p>
<p>Use this option if your consumer is bottlenecked on the multiprocessing step
but also runs time-consuming tasks in the other steps, like <code class="docutils literal notranslate"><span class="pre">Produce</span></code> or
<code class="docutils literal notranslate"><span class="pre">Unfold</span></code>. By prefetching batches, the pool can immediately start working
on the next batch while the current batch is being sent through the next
steps.</p>
</section>
<section id="how-to-tune-your-consumer">
<h2>How to tune your consumer<a class="headerlink" href="#how-to-tune-your-consumer" title="Link to this heading">Â¶</a></h2>
<p>Note that it doesnât make sense to fix output overflow without fixing input
overflow first. If you increase output block size to get rid of output
overflows, then increase input block size, your effective batch size may
increase to a point where you encounter output overflow again. If you
encounter a lot of issues at once, best to fix them in this order:</p>
<ol class="arabic simple">
<li><p>First, tune <code class="docutils literal notranslate"><span class="pre">input_block_size</span></code> to fix input overflow. This will
increase average/effective batch size. Alternatively, set it to <cite>None</cite>
(default) to let arroyo auto-tune it.</p></li>
<li><p>Then, tune <code class="docutils literal notranslate"><span class="pre">max_batch_size</span></code> and <code class="docutils literal notranslate"><span class="pre">max_batch_time</span></code> so that you get the
highest throughput. Test this by running your consumer on a backlog of
messages and look at consumer offset rate (vs broker/total offset rate),
or time it takes to get consumer lag back to normal. For as long as you
have enough RAM, increment it in large steps (like 2x) and fine-tune
afterwards.</p></li>
<li><p>Then, tune <code class="docutils literal notranslate"><span class="pre">output_block_size</span></code> to fix output overflow. If in your
previous tests there was a lot of output overflow, this will remove a lot
of CPU load from your consumer and potentially also increase throughput.</p></li>
<li><p>Now take a look at the <code class="docutils literal notranslate"><span class="pre">batch.backpressure</span></code> metric. If it is emitted,
you need to optimize the next strategy (<code class="docutils literal notranslate"><span class="pre">next_step</span></code>) because thatâs what
youâre bottlenecked on. If it is not emitted, you may need to increase
<code class="docutils literal notranslate"><span class="pre">num_processes</span></code> or increase batch size, so that
<cite>RunTaskWithMultiprocessing</cite> itself is not the bottleneck.</p></li>
</ol>
</section>
</dd></dl>

</section>

        </article><button class="back-to-top" type="button">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
  </svg>
  <span>Back to top</span>
</button><div class="navigation flex print:hidden"><div class="navigation-prev">
    <a href="run_task_in_threads.html">
      <i class="i-lucide chevron-left"></i>
      <div class="page-info">
        <span>Previous</span><div class="title">Run Task in Threads</div></div>
    </a>
  </div><div class="navigation-next">
    <a href="produce.html">
      <div class="page-info">
        <span>Next</span>
        <div class="title">Produce</div>
      </div>
      <i class="i-lucide chevron-right"></i>
    </a>
  </div></div></div>
    </div>
  </main>
</div>
<footer class="sy-foot">
  <div class="sy-foot-inner sy-container mx-auto">
    <div class="sy-foot-reserved md:flex justify-between items-center">
      <div class="sy-foot-copyright"><p>2023, Sentry Team and Contributors</p>
  
  <p>
    Made with
    
    <a href="https://www.sphinx-doc.org/">Sphinx</a> and
    
    <a href="https://shibuya.lepture.com">Shibuya theme</a>.
  </p>
</div>
      <div class="sy-foot-socials"></div>
    </div>
  </div>
</footer>
      <script src="../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/shibuya.js?v=9b0e4dde"></script>
      <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
      <script>mermaid.initialize({startOnLoad:true});</script></body>
</html>